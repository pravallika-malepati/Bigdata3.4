                          HDFS
                   Assignment 3.4

1)HDFS federation and high availability
     HDFS FEDERATION:
            *In Hadoop1.x, the main drawback is single point failure i.e.,if the name node fails then there is nothing to do with HDFS.
            *To overcome that, we go for HDFS Federation where multiple  name nodes are available.
            *Each name node store fsimage, edits and  block mappings of different portions of HDFS.
            *Not all the name node have access to all the datanodes in the cluster.
            *When NameNodes do not have sufficient RAM to store block  mapping of the entire HDFS and availabilty is to be improved,
              HDFS Federation is used.
            *For example ,Namenode1(NN1) has access to datanode1(DN1) and datanode2(DN2) and namenode2(NN2) has access over datanode 2 and 3(DN2,DN3)
                                    If NN1 fails, then NN2 can access blocks of data inDN2 but data onDN1 can't be retrieved.
                                    This is the drawback in HDFS Federation.
                                    This can be overcome in high availability.
    HIGH AVAILABILITY:
          *Two name nodes are available 1.active 2.standby
          *Both the namenodes hold the same information about the datanodes and share edit log information.
          *Whenever active namenode goes down, standby namenode takes up the duty of active namenode.
          *Secondary namenode's function is done by standby namenode.
          *StandbyNameNode takes periodic checkpoints of the active Namenode.

2)How HDFS handles failures while writing data:
   Handling Failures During Writing a File
              *The pipeline is closed and any packets in the ackqueue are added to the front of the data queue
              *The current block on the good DataNodes is given a new identity, which is communicated to the NameNode
              *The failed DataNode is removed from the pipeline, and a new pipeline is constructed from the two good DataNodes
              *The remainder of the block’s data is written to the good DataNodes in the pipeline 
              *The NameNode notices that the block is under-replicated, and it arranges for a further replica to be created on another node
              *As long as dfs.namenode.replication.min replicas (which defaults to 1) are written, the write will succeed
              *The block will be asynchronously replicated across the cluster until its target replication factor is reached (dfs.replication, which defaults to 3)